{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "653ad1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318b2396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Columns:\n",
      "['css-175oi2r href', 'css-9pa8cd src', 'css-1jxf684', 'css-1jxf684 2', 'css-1jxf684 3', 'css-146c3p1', 'css-1jxf684 4', 'css-1jxf684 5', 'css-1jxf684 6', 'css-1jxf684 8', 'css-1jxf684 9', 'css-1jxf684 11', 'css-1jxf684 12', 'css-1jxf684 13', 'css-1jxf684 19', 'css-146c3p1 4', 'css-1jxf684 href 3', 'css-1jxf684 25', 'css-1jxf684 26', 'css-1jxf684 href 4', 'css-1jxf684 27']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Twitter dataset\n",
    "twitter_df = pd.read_csv(\"Tweeter_data.csv\")\n",
    "\n",
    "# Step 2: View column names\n",
    "print(\"Original Columns:\")\n",
    "print(twitter_df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b45391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Rows:\n",
      "            css-175oi2r href  \\\n",
      "0   https://x.com/BlendrNews   \n",
      "1    https://x.com/valdombre   \n",
      "2  https://x.com/Tablesalt13   \n",
      "\n",
      "                                      css-9pa8cd src    css-1jxf684  \\\n",
      "0  https://pbs.twimg.com/profile_images/178314674...     BlendrNews   \n",
      "1  https://pbs.twimg.com/profile_images/188231606...  Riley Donovan   \n",
      "2  https://pbs.twimg.com/profile_images/192265124...      Tablesalt   \n",
      "\n",
      "  css-1jxf684 2 css-1jxf684 3 css-146c3p1  \\\n",
      "0   @BlendrNews             ·      May 14   \n",
      "1    @valdombre             ·       Jun 8   \n",
      "2  @Tablesalt13             ·      Jun 26   \n",
      "\n",
      "                                   css-1jxf684 4 css-1jxf684 5  \\\n",
      "0  Canada faces an economic crossroads:\\r\\n\\r\\n-  Unemployment   \n",
      "1                                       Canada's  unemployment   \n",
      "2                                       BREAKING      CANADIAN   \n",
      "\n",
      "                                       css-1jxf684 6 css-1jxf684 8  ...  \\\n",
      "0  rose to 6.9%\\r\\n- 15.4% of young men are joble...            59  ...   \n",
      "1  rate has now hit 7%. \\r\\n\\r\\nWhy is the federa...           388  ...   \n",
      "2                                              YOUTH           139  ...   \n",
      "\n",
      "  css-1jxf684 11 css-1jxf684 12  \\\n",
      "0            39K            NaN   \n",
      "1           117K            NaN   \n",
      "2            68K   UNEMPLOYMENT   \n",
      "\n",
      "                                      css-1jxf684 13 css-1jxf684 19  \\\n",
      "0                                                NaN            NaN   \n",
      "1                                                NaN            NaN   \n",
      "2  INCREASING FASTER THAN ANY OTHER ADVANCED NATI...            NaN   \n",
      "\n",
      "  css-146c3p1 4 css-1jxf684 href 3 css-1jxf684 25 css-1jxf684 26  \\\n",
      "0           NaN                NaN            NaN            NaN   \n",
      "1           NaN                NaN            NaN            NaN   \n",
      "2           NaN                NaN            NaN            NaN   \n",
      "\n",
      "  css-1jxf684 href 4 css-1jxf684 27  \n",
      "0                NaN            NaN  \n",
      "1                NaN            NaN  \n",
      "2                NaN            NaN  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Display first few rows\n",
    "print(\"\\nSample Rows:\")\n",
    "print(twitter_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210edda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "css-175oi2r href         1\n",
      "css-9pa8cd src           1\n",
      "css-1jxf684              4\n",
      "css-1jxf684 2            0\n",
      "css-1jxf684 3            1\n",
      "css-146c3p1              1\n",
      "css-1jxf684 4          123\n",
      "css-1jxf684 5           54\n",
      "css-1jxf684 6          172\n",
      "css-1jxf684 8          671\n",
      "css-1jxf684 9         1067\n",
      "css-1jxf684 11          24\n",
      "css-1jxf684 12         180\n",
      "css-1jxf684 13         328\n",
      "css-1jxf684 19        1170\n",
      "css-146c3p1 4          616\n",
      "css-1jxf684 href 3     573\n",
      "css-1jxf684 25         552\n",
      "css-1jxf684 26        1147\n",
      "css-1jxf684 href 4    1097\n",
      "css-1jxf684 27        1098\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(twitter_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b328dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "css-175oi2r href       0.064516\n",
      "css-9pa8cd src         0.064516\n",
      "css-1jxf684            0.258065\n",
      "css-1jxf684 2          0.000000\n",
      "css-1jxf684 3          0.064516\n",
      "css-146c3p1            0.064516\n",
      "css-1jxf684 4          7.935484\n",
      "css-1jxf684 5          3.483871\n",
      "css-1jxf684 6         11.096774\n",
      "css-1jxf684 8         43.290323\n",
      "css-1jxf684 9         68.838710\n",
      "css-1jxf684 11         1.548387\n",
      "css-1jxf684 12        11.612903\n",
      "css-1jxf684 13        21.161290\n",
      "css-1jxf684 19        75.483871\n",
      "css-146c3p1 4         39.741935\n",
      "css-1jxf684 href 3    36.967742\n",
      "css-1jxf684 25        35.612903\n",
      "css-1jxf684 26        74.000000\n",
      "css-1jxf684 href 4    70.774194\n",
      "css-1jxf684 27        70.838710\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(twitter_df.isnull().mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fb8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows: 62\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Count duplicates\n",
    "print(\"\\nDuplicate Rows:\", twitter_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2ca36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Drop duplicates\n",
    "twitter_cleaned = twitter_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c686990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Drop columns with >70% missing values\n",
    "threshold = len(twitter_cleaned) * 0.7\n",
    "twitter_cleaned = twitter_cleaned.dropna(thresh=threshold, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Step 8: Rename only important columns\n",
    "twitter_df = twitter_df.rename(columns={\n",
    "    'css-1jxf684 4': 'tweet_text',           # Main tweet text\n",
    "    'css-146c3p1': 'date',                   # Posting date\n",
    "    'css-1jxf684 8': 'likes',                # Like count\n",
    "    'css-1jxf684 11': 'retweets',            # Retweet count\n",
    "    'css-1jxf684 5': 'keyword_from_tweets'   # Topic/keyword\n",
    "})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8fafe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Combine multiple text columns to get full tweet\n",
    "# Many parts of tweets are spread across css-1jxf684 columns\n",
    "text_columns = [col for col in twitter_df.columns if 'css-1jxf684' in col]\n",
    "twitter_df['tweet_text'] = twitter_df[text_columns].fillna('').apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Rename important columns with comments\n",
    "twitter_df = twitter_df.rename(columns={\n",
    "    'css-146c3p1': 'date',                # Posting date of the tweet\n",
    "    'css-1jxf684 8': 'likes',             # Number of likes\n",
    "    'css-1jxf684 11': 'retweets',         # Number of retweets\n",
    "    'css-1jxf684 5': 'keyword_from_tweets'  # Extracted keyword/topic\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afc890ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8.1: Clean tweet_text (remove usernames, first word, bullet symbols, URLs, extra spaces)\n",
    "import re\n",
    "\n",
    "def clean_tweet(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'@\\w+', '', text)        # Remove @usernames\n",
    "    text = re.sub(r'·', '', text)           # Remove bullet symbol\n",
    "    text = re.sub(r'http\\S+', '', text)     # Remove URLs\n",
    "    words = text.split()\n",
    "    text = ' '.join(words[1:]) if len(words) > 1 else text  # Remove first word (username-like)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "twitter_df['tweet_text'] = twitter_df['tweet_text'].apply(clean_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27251c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Keep only the required columns from the DataFrame\n",
    "#  want to keep: tweet text, date, likes, retweets, and keywords\n",
    "twitter_cleaned = twitter_df[['tweet_text', 'date', 'likes', 'retweets', 'keyword_from_tweets']]\n",
    "\n",
    "# Save the cleaned DataFrame into a new CSV file\n",
    "twitter_cleaned.to_csv(\"twitter_cleaned.csv\", index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d4b695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Shape: (1550, 5)\n",
      "\n",
      "Cleaned & Filtered Sample:\n",
      "                                          tweet_text    date likes retweets  \\\n",
      "0  Canada faces an economic crossroads: - Unemplo...  May 14    59      39K   \n",
      "1  Donovan Canada's unemployment rate has now hit...   Jun 8   388     117K   \n",
      "2  BREAKING CANADIAN YOUTH 139 696 68K UNEMPLOYME...  Jun 26   139      68K   \n",
      "\n",
      "  keyword_from_tweets  \n",
      "0        Unemployment  \n",
      "1        unemployment  \n",
      "2            CANADIAN  \n"
     ]
    }
   ],
   "source": [
    "# Step 10: Show final shape and preview\n",
    "print(\"\\nFinal Shape:\", twitter_cleaned.shape)\n",
    "print(\"\\nCleaned & Filtered Sample:\")\n",
    "print(twitter_cleaned.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c87a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Save the cleaned DataFrame to CSV\n",
    "twitter_cleaned.to_csv(\"twitter_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce516478",
   "metadata": {},
   "source": [
    "## Preprocessing Labour stats data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4e52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "employment_df = pd.read_csv('Employment by class of worker and industry, seasonally adjusted.csv', skiprows=1)\n",
    "labour_df = pd.read_csv('Labour force characteristics by province, seasonally adjusted.csv', skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39505cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Employment Data ===\n",
      "Initial Shape: (33, 8)\n",
      "\n",
      "Null values:\n",
      "                            3\n",
      " April 2025                9\n",
      " May 2025                  9\n",
      " Standard error{1}         9\n",
      " April to May 2025         9\n",
      " May 2024 to May 2025      9\n",
      " April to May 2025.1       9\n",
      " May 2024 to May 2025.1    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -------------------- Employment by class of worker and industry DATA CLEANING --------------------\n",
    "print(\"=== Employment Data ===\")\n",
    "print(\"Initial Shape:\", employment_df.shape)\n",
    "print(\"\\nNull values:\\n\", employment_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b65d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null values per column:\n",
      "                           3\n",
      " April 2025                9\n",
      " May 2025                  9\n",
      " Standard error{1}         9\n",
      " April to May 2025         9\n",
      " May 2024 to May 2025      9\n",
      " April to May 2025.1       9\n",
      " May 2024 to May 2025.1    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Check null & missing values\n",
    "print(\"\\nNull values per column:\")\n",
    "print(employment_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f71bf181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            9.090909\n",
      " April 2025                27.272727\n",
      " May 2025                  27.272727\n",
      " Standard error{1}         27.272727\n",
      " April to May 2025         27.272727\n",
      " May 2024 to May 2025      27.272727\n",
      " April to May 2025.1       27.272727\n",
      " May 2024 to May 2025.1    27.272727\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(employment_df.isnull().mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a143b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xa0', '\\xa0April 2025', '\\xa0May 2025', '\\xa0Standard error{1}', '\\xa0April to May 2025', '\\xa0May 2024 to May 2025', '\\xa0April to May 2025.1', '\\xa0May 2024 to May 2025.1']\n"
     ]
    }
   ],
   "source": [
    "print([col for col in employment_df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61442599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['', 'April 2025', 'May 2025', 'Standard error{1}', 'April to May 2025',\n",
      "       'May 2024 to May 2025', 'April to May 2025.1',\n",
      "       'May 2024 to May 2025.1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "employment_df.columns = employment_df.columns.str.strip()\n",
    "print(employment_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3eb8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class_of_worker', 'april_2025', 'may_2025', 'standard_error',\n",
      "       'change_apr_may_2025', 'change_may2024_may2025',\n",
      "       'pct_change_apr_may_2025', 'pct_change_may2024_may2025'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "employment_df.rename(columns={\n",
    "    '': 'class_of_worker',\n",
    "    'April 2025': 'april_2025',\n",
    "    'May 2025': 'may_2025',\n",
    "    'Standard error{1}': 'standard_error',\n",
    "    'April to May 2025': 'change_apr_may_2025',\n",
    "    'May 2024 to May 2025': 'change_may2024_may2025',\n",
    "    'April to May 2025.1': 'pct_change_apr_may_2025',\n",
    "    'May 2024 to May 2025.1': 'pct_change_may2024_may2025'\n",
    "}, inplace=True)\n",
    "print(employment_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3bd0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all values are NaN\n",
    "employment_df.dropna(how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f731c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class_of_worker', 'april_2025', 'may_2025', 'standard_error',\n",
      "       'change_apr_may_2025', 'change_may2024_may2025',\n",
      "       'pct_change_apr_may_2025', 'pct_change_may2024_may2025'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(employment_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9056ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numeric:\n",
    "for col in employment_df.columns[1:]:\n",
    "    employment_df[col] = pd.to_numeric(employment_df[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b771fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN with median:\n",
    "numeric_cols = employment_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "employment_df[numeric_cols] = employment_df[numeric_cols].fillna(employment_df[numeric_cols].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a81a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\birva\\AppData\\Local\\Temp\\ipykernel_14256\\3484244376.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  employment_df['class_of_worker'] = employment_df['class_of_worker'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Fill the first column (class_of_worker) with forward fill:\n",
    "employment_df['class_of_worker'] = employment_df['class_of_worker'].fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61956432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employment_df.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9736e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove rows that contain keywords like \"Note\", \"Source\", \"Table\"\n",
    "employment_df = employment_df[~employment_df['class_of_worker'].str.contains(\"Note|Source|Table|rounding\", case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7745744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\birva\\AppData\\Local\\Temp\\ipykernel_14256\\1135438297.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  employment_df['class_of_worker'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "employment_df['class_of_worker'].fillna('Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d10c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_of_worker               0.0\n",
      "april_2025                    0.0\n",
      "may_2025                      0.0\n",
      "standard_error                0.0\n",
      "change_apr_may_2025           0.0\n",
      "change_may2024_may2025        0.0\n",
      "pct_change_apr_may_2025       0.0\n",
      "pct_change_may2024_may2025    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(employment_df.isnull().mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cc7411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_df.to_csv(\"employment_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6f12fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Labour force characteristics by province, seasonally adjusted ===\n",
      "Initial Shape: (117, 8)\n",
      "\n",
      "Null values:\n",
      "                            11\n",
      " April 2025                26\n",
      " May 2025                  26\n",
      " Standard error{1}         26\n",
      " April to May 2025         26\n",
      " May 2024 to May 2025      26\n",
      " April to May 2025.1       26\n",
      " May 2024 to May 2025.1    26\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## -------------------- Labour force characteristics by province DATA CLEANING --------------------\n",
    "print(\"=== Labour force characteristics by province, seasonally adjusted ===\")\n",
    "print(\"Initial Shape:\", labour_df.shape)\n",
    "print(\"\\nNull values:\\n\", labour_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1831a550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            9.401709\n",
      " April 2025                22.222222\n",
      " May 2025                  22.222222\n",
      " Standard error{1}         22.222222\n",
      " April to May 2025         22.222222\n",
      " May 2024 to May 2025      22.222222\n",
      " April to May 2025.1       22.222222\n",
      " May 2024 to May 2025.1    22.222222\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(labour_df.isnull().mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d208035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xa0', '\\xa0April 2025', '\\xa0May 2025', '\\xa0Standard error{1}', '\\xa0April to May 2025', '\\xa0May 2024 to May 2025', '\\xa0April to May 2025.1', '\\xa0May 2024 to May 2025.1']\n"
     ]
    }
   ],
   "source": [
    "print([col for col in labour_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "393e8c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['', 'April 2025', 'May 2025', 'Standard error{1}', 'April to May 2025',\n",
      "       'May 2024 to May 2025', 'April to May 2025.1',\n",
      "       'May 2024 to May 2025.1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "labour_df.columns = labour_df.columns.str.strip()\n",
    "print(labour_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "71f168c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labour_df.rename(columns={\n",
    "    ' ': 'province',\n",
    "    'April 2025': 'april_2025',\n",
    "    'May 2025': 'may_2025',\n",
    "    'Standard error{1}': 'standard_error',\n",
    "    'April to May 2025': 'change_apr_may_2025',\n",
    "    'May 2024 to May 2025': 'change_may2024_may2025',\n",
    "    'April to May 2025.1': 'pct_change_apr_may_2025',\n",
    "    'May 2024 to May 2025.1': 'pct_change_may2024_may2025'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "76456eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Drop rows where all values are NaN\n",
    "labour_df.dropna(how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "91deecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Fill text column (province) using forward fill\n",
    "if 'province' in labour_df.columns:\n",
    "    labour_df['province'] = labour_df['province'].fillna(method='ffill')\n",
    "    labour_df['province'] = labour_df['province'].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5534452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert numeric columns to float and fill with median\n",
    "for col in labour_df.columns[1:]:\n",
    "    labour_df[col] = pd.to_numeric(labour_df[col], errors='coerce')\n",
    "\n",
    "numeric_cols = labour_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "labour_df[numeric_cols] = labour_df[numeric_cols].fillna(labour_df[numeric_cols].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d9bcabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              0.934579\n",
      "april_2025                    0.000000\n",
      "may_2025                      0.000000\n",
      "standard_error                0.000000\n",
      "change_apr_may_2025           0.000000\n",
      "change_may2024_may2025        0.000000\n",
      "pct_change_apr_may_2025       0.000000\n",
      "pct_change_may2024_may2025    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(labour_df.isnull().mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "32091c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labour force data cleaned and saved to labour_force_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    " ## Save the cleaned CSV\n",
    "labour_df.to_csv('labour_force_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Labour force data cleaned and saved to labour_force_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbc688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
